{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc2804",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!sudo apt update && sudo apt install ffmpeg\n",
    "#!sudo apt-get install libportaudio2 portaudio19-dev\n",
    "#!sudo apt install python3-gi python3-gi-cairo gir1.2-gobject-2.0 gir1.2-gstreamer-1.0 gstreamer1.0-plugins-good gstreamer1.0-plugins-base gstreamer1.0-gl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e54c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai-whisper sounddevice scipy ollama pyttsx3 numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114708c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install edge-tts playsound==1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63836bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a5760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wav\n",
    "import whisper\n",
    "import ollama\n",
    "# import pyttsx3 # Ya no usamos pyttsx3\n",
    "import edge_tts # ¡Nuevo!\n",
    "from playsound import playsound # ¡Nuevo!\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "import asyncio # ¡Nuevo!\n",
    "from pydub import AudioSegment\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae834a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuración ---\n",
    "SAMPLE_RATE = 16000\n",
    "RECORD_SECONDS = 5\n",
    "SILENCE_THRESHOLD = 0.01\n",
    "WHISPER_MODEL = \"base\"\n",
    "OLLAMA_MODEL = \"llama3.2:1b\" # O \"llama3.2:1b\" si lo tienes\n",
    "TEMP_AUDIO_FILE_REC = \"temp_recording.wav\"\n",
    "TEMP_AUDIO_FILE_TTS = \"temp_tts_output.mp3\" # Archivo para la salida de edge-tts\n",
    "EXIT_KEYWORDS = [\"adiós\", \"terminar\", \"salir\", \"bye\", \"exit\"]\n",
    "MICROPHONE_DEVICE_INDEX = None # Ajusta si es necesario\n",
    "# --- Configuración de Voz TTS (edge-tts) ---\n",
    "# Elige una voz de la lista obtenida con 'edge-tts --list-voices'\n",
    "# Ejemplos: \"es-ES-AlvaroNeural\", \"es-ES-ElviraNeural\", \"es-MX-JorgeNeural\"\n",
    "TTS_VOICE = \"es-ES-ElviraNeural\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b68651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buscando dispositivos de audio...\n",
      "   0 HDA NVidia: HDMI 0 (hw:0,3), ALSA (0 in, 8 out)\n",
      "   1 HDA NVidia: HDMI 1 (hw:0,7), ALSA (0 in, 8 out)\n",
      "   2 HDA NVidia: HDMI 2 (hw:0,8), ALSA (0 in, 8 out)\n",
      "   3 HDA NVidia: HDMI 3 (hw:0,9), ALSA (0 in, 8 out)\n",
      "   4 sof-hda-dsp: - (hw:1,0), ALSA (2 in, 2 out)\n",
      "   5 sof-hda-dsp: - (hw:1,3), ALSA (0 in, 2 out)\n",
      "   6 sof-hda-dsp: - (hw:1,4), ALSA (0 in, 2 out)\n",
      "   7 sof-hda-dsp: - (hw:1,5), ALSA (0 in, 2 out)\n",
      "   8 sof-hda-dsp: - (hw:1,6), ALSA (2 in, 0 out)\n",
      "   9 sof-hda-dsp: - (hw:1,7), ALSA (2 in, 0 out)\n",
      "  10 hdmi, ALSA (0 in, 8 out)\n",
      "  11 pulse, ALSA (32 in, 32 out)\n",
      "* 12 default, ALSA (32 in, 32 out)\n",
      "Dispositivo de entrada predeterminado del sistema: 12\n",
      "Usando dispositivo de entrada con índice: 12\n"
     ]
    }
   ],
   "source": [
    "# --- Listar Dispositivos de Audio (para diagnóstico) ---\n",
    "# (Mantenemos la lógica de detección de micrófono de la versión anterior)\n",
    "print(\"Buscando dispositivos de audio...\")\n",
    "try:\n",
    "    print(sd.query_devices())\n",
    "    default_input_device = sd.default.device[0]\n",
    "    print(f\"Dispositivo de entrada predeterminado del sistema: {default_input_device}\")\n",
    "    if MICROPHONE_DEVICE_INDEX is None:\n",
    "        MICROPHONE_DEVICE_INDEX = default_input_device\n",
    "    print(f\"Usando dispositivo de entrada con índice: {MICROPHONE_DEVICE_INDEX}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al consultar dispositivos de audio: {e}. Usando predeterminado si es posible.\")\n",
    "    # No salimos, intentaremos continuar con el predeterminado si falla la consulta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "381bf404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando modelo Whisper...\n",
      "Modelo Whisper 'base' cargado.\n",
      "Configurado para usar la voz TTS: es-ES-ElviraNeural (requiere internet)\n"
     ]
    }
   ],
   "source": [
    "# --- Inicialización Whisper ---\n",
    "print(\"Cargando modelo Whisper...\")\n",
    "try:\n",
    "    whisper_model = whisper.load_model(WHISPER_MODEL)\n",
    "    print(f\"Modelo Whisper '{WHISPER_MODEL}' cargado.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando el modelo Whisper: {e}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# --- Inicialización TTS (edge-tts) ---\n",
    "# No hay inicialización explícita como en pyttsx3, se hace al usarlo.\n",
    "print(f\"Configurado para usar la voz TTS: {TTS_VOICE} (requiere internet)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c6d11d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Funciones (algunas ahora son async) ---\n",
    "\n",
    "def record_audio(filename, duration, samplerate, device_index):\n",
    "    \"\"\"Graba audio del micrófono especificado y lo guarda en un archivo WAV.\"\"\"\n",
    "    # Esta función no necesita ser async\n",
    "    print(f\"\\nComenzando grabación desde dispositivo {device_index} ({duration} segundos)... Habla ahora.\")\n",
    "    try:\n",
    "        recording = sd.rec(int(duration * samplerate), samplerate=samplerate, channels=1, dtype='int16', device=device_index)\n",
    "        sd.wait()\n",
    "        print(\"Grabación finalizada.\")\n",
    "        wav.write(filename, samplerate, recording)\n",
    "        if np.abs(recording).mean() < SILENCE_THRESHOLD * np.iinfo(recording.dtype).max:\n",
    "            print(\"Advertencia: Se detectó silencio o audio muy bajo.\")\n",
    "            return False\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la grabación: {e}\")\n",
    "        print(\"Verifica el índice del dispositivo y los permisos.\")\n",
    "        return None\n",
    "\n",
    "def transcribe_audio(filename, model):\n",
    "    \"\"\"Transcribe el archivo de audio usando Whisper.\"\"\"\n",
    "    # Esta función no necesita ser async\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Error: El archivo de audio {filename} no existe.\")\n",
    "        return None\n",
    "    print(\"Transcribiendo audio...\")\n",
    "    try:\n",
    "        # Forzar español puede ayudar a Whisper, y es coherente con la voz TTS\n",
    "        result = model.transcribe(filename, fp16=False, language='es')\n",
    "        transcription = result[\"text\"].strip()\n",
    "        print(f\"Texto reconocido: '{transcription}'\")\n",
    "        # Limpiar archivo temporal de grabación AQUÍ, después de transcribir\n",
    "        if os.path.exists(filename):\n",
    "             try:\n",
    "                 os.remove(filename)\n",
    "             except Exception as e_del:\n",
    "                 print(f\"Advertencia: No se pudo eliminar {filename}: {e_del}\")\n",
    "        return transcription\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la transcripción: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_llm_response(prompt, model_name, conversation_history):\n",
    "    \"\"\"Obtiene una respuesta del modelo Ollama manteniendo el historial.\"\"\"\n",
    "    # Esta función no necesita ser async\n",
    "    print(f\"Enviando a Ollama (modelo: {model_name})...\")\n",
    "    try:\n",
    "        conversation_history.append({'role': 'user', 'content': prompt})\n",
    "        response = ollama.chat(\n",
    "            model=model_name,\n",
    "            messages=conversation_history\n",
    "        )\n",
    "        llm_response = response['message']['content']\n",
    "        conversation_history.append({'role': 'assistant', 'content': llm_response})\n",
    "        print(f\"Respuesta de Ollama: '{llm_response}'\")\n",
    "        return llm_response\n",
    "    except Exception as e:\n",
    "        print(f\"Error contactando con Ollama: {e}\")\n",
    "        if conversation_history and conversation_history[-1]['role'] == 'user':\n",
    "            conversation_history.pop()\n",
    "        return \"Lo siento, no pude procesar tu solicitud en este momento.\"\n",
    "\n",
    "async def speak_text_edge(text, voice, output_filename):\n",
    "    \"\"\"Genera el audio TTS usando edge-tts y lo reproduce con pydub + sounddevice.\"\"\"\n",
    "    print(\"Generando voz con edge-tts...\")\n",
    "    try:\n",
    "        # 1. Generar el archivo MP3 con edge-tts\n",
    "        communicate = edge_tts.Communicate(text, voice)\n",
    "        await communicate.save(output_filename)\n",
    "\n",
    "        print(\"Reproduciendo respuesta con pydub + sounddevice...\")\n",
    "\n",
    "        # 2. Cargar el MP3 usando pydub\n",
    "        # Asegúrate de que ffmpeg esté instalado y en el PATH\n",
    "        audio = AudioSegment.from_mp3(output_filename)\n",
    "\n",
    "        # 3. Obtener los datos de audio como un array numpy\n",
    "        # Convertir a un tipo de dato que sounddevice entienda bien (float32 o int16)\n",
    "        # Pydub usa int16 internamente para MP3 estándar\n",
    "        samples = np.array(audio.get_array_of_samples())\n",
    "\n",
    "        # Asegurarse de que es la forma correcta para sounddevice (N_muestras, N_canales)\n",
    "        if audio.channels > 1:\n",
    "            samples = samples.reshape((-1, audio.channels))\n",
    "        # else: # Si es mono, puede necesitar ser (N_muestras, 1) o simplemente (N_muestras,)\n",
    "              # sounddevice suele manejar bien arrays 1D para mono.\n",
    "              # samples = samples.reshape((-1, 1)) # Descomentar si da error de forma\n",
    "\n",
    "        # 4. Reproducir usando sounddevice\n",
    "        sd.play(samples, audio.frame_rate, blocking=True)\n",
    "        # Alternativa si blocking=True no funciona bien con asyncio:\n",
    "        # sd.play(samples, audio.frame_rate)\n",
    "        # sd.wait() # Espera a que termine la reproducción\n",
    "\n",
    "        print(\"Reproducción finalizada.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "         print(f\"Error: No se pudo encontrar ffmpeg. Asegúrate de que esté instalado y en el PATH del sistema.\")\n",
    "         print(\"Puedes instalarlo con 'sudo apt install ffmpeg' o 'sudo dnf install ffmpeg'.\")\n",
    "    except edge_tts.exceptions.NoAudioReceived:\n",
    "        print(\"Error: No se recibió audio de edge-tts. Verifica la conexión a internet y la voz seleccionada.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error durante la síntesis o reproducción de voz: {e}\")\n",
    "    finally:\n",
    "        # 5. Limpiar el archivo de audio TTS temporal (importante)\n",
    "        if os.path.exists(output_filename):\n",
    "            try:\n",
    "                os.remove(output_filename)\n",
    "            except Exception as e:\n",
    "                print(f\"Advertencia: No se pudo eliminar {output_filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1c8e81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Bucle Principal Asíncrono ---\n",
    "async def main_loop():\n",
    "    conversation_history = []\n",
    "    print(\"\\n--- Asistente de Voz (con edge-tts) Iniciado ---\")\n",
    "    print(f\"Usando voz: {TTS_VOICE}\")\n",
    "    print(f\"Di una de las siguientes palabras para salir: {', '.join(EXIT_KEYWORDS)}\")\n",
    "    print(\"Recuerda presionar Enter antes de cada vez que quieras hablar.\")\n",
    "\n",
    "    while True:\n",
    "        # Usamos run_in_executor para manejar input() síncrono en un loop async\n",
    "        # O simplemente podemos dejar input() como está si no causa problemas\n",
    "        await asyncio.to_thread(input, \"\\nPresiona Enter para comenzar a grabar...\")\n",
    "\n",
    "\n",
    "        # 1. Grabar audio (síncrono)\n",
    "        recording_result = record_audio(TEMP_AUDIO_FILE_REC, RECORD_SECONDS, SAMPLE_RATE, MICROPHONE_DEVICE_INDEX)\n",
    "\n",
    "        if recording_result is None:\n",
    "             # Error de grabación, ya se imprimió mensaje en la función\n",
    "             # Podríamos querer decir algo aquí también\n",
    "             await speak_text_edge(\"Hubo un problema con la grabación.\", TTS_VOICE, TEMP_AUDIO_FILE_TTS)\n",
    "             continue\n",
    "        elif not recording_result: # Silencio detectado\n",
    "            retry_input = await asyncio.to_thread(input, \"No detecté sonido claro. ¿Quieres intentarlo de nuevo? (s/n): \")\n",
    "            if retry_input.lower() != 's':\n",
    "                 await speak_text_edge(\"Entendido, terminando la sesión.\", TTS_VOICE, TEMP_AUDIO_FILE_TTS)\n",
    "                 break\n",
    "            else:\n",
    "                 # No es necesario borrar aquí, transcribe_audio lo hará si existe\n",
    "                 continue\n",
    "\n",
    "        # 2. Transcribir audio (síncrono, pero la función limpia el archivo REC)\n",
    "        user_text = transcribe_audio(TEMP_AUDIO_FILE_REC, whisper_model)\n",
    "\n",
    "        if not user_text:\n",
    "            await speak_text_edge(\"No pude entender lo que dijiste. Por favor, inténtalo de nuevo.\", TTS_VOICE, TEMP_AUDIO_FILE_TTS)\n",
    "            continue\n",
    "\n",
    "        # 3. Comprobar salida\n",
    "        if any(keyword in user_text.lower() for keyword in EXIT_KEYWORDS):\n",
    "            print(\"Detectada palabra clave de salida.\")\n",
    "            await speak_text_edge(\"Entendido. ¡Hasta luego!\", TTS_VOICE, TEMP_AUDIO_FILE_TTS)\n",
    "            break\n",
    "\n",
    "        # 4. Obtener respuesta del LLM (síncrono)\n",
    "        ai_response = get_llm_response(user_text, OLLAMA_MODEL, conversation_history)\n",
    "\n",
    "        # 5. Decir la respuesta (asíncrono)\n",
    "        await speak_text_edge(ai_response, TTS_VOICE, TEMP_AUDIO_FILE_TTS)\n",
    "\n",
    "        # Pequeña pausa asíncrona\n",
    "        await asyncio.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2897fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Asistente de Voz (con edge-tts) Iniciado ---\n",
      "Usando voz: es-ES-ElviraNeural\n",
      "Di una de las siguientes palabras para salir: adiós, terminar, salir, bye, exit\n",
      "Recuerda presionar Enter antes de cada vez que quieras hablar.\n",
      "\n",
      "Comenzando grabación desde dispositivo 12 (5 segundos)... Habla ahora.\n",
      "Grabación finalizada.\n",
      "Transcribiendo audio...\n",
      "Texto reconocido: 'Hola, ¿cómo estás?'\n",
      "Enviando a Ollama (modelo: llama3.2:1b)...\n",
      "Respuesta de Ollama: 'Estoy bien, gracias. ¿Y tú? ¿En qué puedo ayudarte hoy?'\n",
      "Generando voz con edge-tts...\n",
      "Reproduciendo respuesta con pydub + sounddevice...\n",
      "Reproducción finalizada.\n",
      "\n",
      "Comenzando grabación desde dispositivo 12 (5 segundos)... Habla ahora.\n",
      "Grabación finalizada.\n",
      "Transcribiendo audio...\n",
      "Texto reconocido: 'Adiós'\n",
      "Detectada palabra clave de salida.\n",
      "Generando voz con edge-tts...\n",
      "Reproduciendo respuesta con pydub + sounddevice...\n",
      "Reproducción finalizada.\n",
      "--- Asistente de Voz Terminado ---\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Ejecuta directamente la corutina en el bucle existente\n",
    "    await main_loop()\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nInterrupción por teclado detectada. Saliendo...\")\n",
    "finally:\n",
    "    # Limpieza final de archivos temporales si aún existen\n",
    "    if os.path.exists(TEMP_AUDIO_FILE_REC):\n",
    "        try: os.remove(TEMP_AUDIO_FILE_REC)\n",
    "        except Exception: pass\n",
    "    if os.path.exists(TEMP_AUDIO_FILE_TTS):\n",
    "        try: os.remove(TEMP_AUDIO_FILE_TTS)\n",
    "        except Exception: pass\n",
    "    print(\"--- Asistente de Voz Terminado ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
